{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5bc13f",
   "metadata": {},
   "source": [
    "# Exploratory Data analysis\n",
    "\n",
    "### Preprocessing and cleaning\n",
    "\n",
    "1. Columns with null values i.e. emplty columns were removed from the dataset\n",
    "2. The next step to explore data is find descriptive statistics and datat type of the columns\n",
    "3. Many numeric columns were identified as object data type due to special charcters like , $ etc. So the special characteristics were stripped and converted to float type\n",
    "4. \n",
    "2. Two rows were identified with arbitary/irrelevant values in each of the columns, so they were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3913f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "ds = pd.read_csv(\"Assessment_Parcels_20251004.csv\")\n",
    "\n",
    "# Identify columns with 0 non-null values\n",
    "empty_columns = ds.columns[ds.isnull().all()].tolist()\n",
    "\n",
    "# Drop all empty columns except the one to keep\n",
    "columns_to_drop = [col for col in empty_columns ] #if col != column_to_keep\n",
    "ds = ds.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27115e",
   "metadata": {},
   "source": [
    "## Descriptive statistics for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce09b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics for all columns\n",
    "descriptive_stats = ds.describe()\n",
    "\n",
    "# Add median separately since it's not included in describe()\n",
    "descriptive_stats.loc['median'] = ds.median()\n",
    "descriptive_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f27771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da89d36",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "Identified few numerical columns that were of data type 'object'. \n",
    "They have some speical characters like Dollar sign, comma etc that needs to be stripped.\n",
    "\n",
    "After scrubbing, the descriptive statistics of numerical columns is as following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e112b87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Numeric columns with special characters that need cleaning\n",
    "columns_to_clean = ['Street Number','Total Living Area','Total Assessed Value',\n",
    "                    'Assessed Land Area','Water Frontage Measurement','Sewer Frontage Measurement',\n",
    "                    'GISID','Roll Number','Dwelling Units']\n",
    "# Remove the dollar sign and convert to float\n",
    "ds[columns_to_clean] = ds[columns_to_clean].replace('[\\$,]', '', regex=True).astype(float)\n",
    "ds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3704025",
   "metadata": {},
   "source": [
    "## Descriptive statistics of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "324549a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate descriptive statistics for categorical columns\n",
    "categorical_stats = ds.describe(include='object')\n",
    "categorical_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef916927",
   "metadata": {},
   "source": [
    "## Comments:\n",
    "\n",
    "While going through the dataset, two rows were identified with arbitary values, '0107376627423 49.80160863413996' in all the columns, so they were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5f7fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data type of 'Roll Number' to object in order to remove the long random roll number\n",
    "ds['Roll Number'] = ds['Roll Number'].astype(object)\n",
    "\n",
    "# List of record IDs to drop\n",
    "roll_nos_to_drop = ['0107376627423 49.80160863413996', '9257376']\n",
    "\n",
    "# Drop rows where record_id is in the list\n",
    "ds = ds[~ds['Roll Number'].isin(roll_nos_to_drop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1909f8a",
   "metadata": {},
   "source": [
    "# Handling missing data\n",
    "\n",
    "Numerical variables like Total Living Area, Rooms, Water Frontage Measurement, Sewer Frontage Measurement, Total Assessed Value were replaced by Median\n",
    "\n",
    "Categorical Variable like Street Type, Building type, Basement, Basement Finish, Year Built were replaced by mode or by introducing new category \"Missing\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b6fc4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculating number of null values in each column\n",
    "ds.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355ae381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the first unnamed column if it's just an index\n",
    "if ds.columns[0].startswith('Unnamed'):\n",
    "    ds = ds.iloc[:, 1:]\n",
    "\n",
    "# Summary of missing values before imputation\n",
    "missing_before = ds.isnull().sum()\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = ds.select_dtypes(include=['number']).columns\n",
    "categorical_cols = ds.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Handle missing values\n",
    "# For numerical columns: median imputation\n",
    "for col in numerical_cols:\n",
    "    median_value = ds[col].median()\n",
    "    ds[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# For categorical columns: mode imputation or 'Missing' category\n",
    "for col in categorical_cols:\n",
    "    mode_value = ds[col].mode()\n",
    "    if not mode_value.empty:\n",
    "        ds[col].fillna(mode_value[0], inplace=True)\n",
    "    else:\n",
    "        ds[col].fillna('Missing', inplace=True)\n",
    "\n",
    "# Summary of missing values after imputation\n",
    "missing_after = ds.isnull().sum()\n",
    "missing_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc081c2",
   "metadata": {},
   "source": [
    "# Comments:\n",
    "\n",
    "The assignement asked for AVM for RESIDENTIAL PROPERTIES. So the column 'Property Use Code' is used to identify residential properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "555c06c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all unique categories in the 'Property Use Code' column to identify residential properties only\n",
    "unique_categories = ds['Property Use Code'].dropna().unique().tolist()\n",
    "unique_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ddc814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories to filter\n",
    "categories_to_keep = ['RESSD - DETACHED SINGLE DWELLING', 'RESMB - RESIDENTIAL MULTIPLE BUILDINGS',\n",
    "                     'RESSS - SIDE BY SIDE','RESSS - SIDE BY SIDE','RESMH - MOBILE HOME',\n",
    "                      'RESRM - ROOMING HOUSE','RESDU - DUPLEX','RESTR - TRIPLEX','RESRH - ROW HOUSING',\n",
    "                      'RESMC - MULTIFAMILY CONVERSION','RESGC - RESIDENTIAL GROUP CARE',\n",
    "                      'RESOT - RESIDENTIAL OUTBUILDING','RESSU - RESIDENTIAL SECONDARY UNIT',\n",
    "                      'RESMA - MULTIPLE ATTACHED UNITS','RESMU - RESIDENTIAL MULTIPLE USE',\n",
    "                      'RESAM - APARTMENTS MULTIPLE USE','RESAP - APARTMENTS','CNRES - CONDO RESIDENTIAL'\n",
    "                     ]\n",
    "\n",
    "# Filter the DataFrame to include only rows with specified residential type\n",
    "ds = ds[ds['Property Use Code'].isin(categories_to_keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856a629",
   "metadata": {},
   "source": [
    "# Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c37cbe28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select only numerical features for correlation analysis\n",
    "numerical_dataset = ds.select_dtypes(include=['number'])\n",
    "correlation=numerical_dataset.corr()\n",
    "print(correlation['Total Assessed Value'].sort_values(ascending=False),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99542cb1",
   "metadata": {},
   "source": [
    "# Comment:\n",
    "\n",
    "As per correlation analysis, dropping column 'Current Assessment Year', 'GISD','Street number', 'Centroid Lon', 'Centroid Lat'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af7c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cols_to_drop = ['Street Number','Current Assessment Year','GISID','Centroid Lon','Centroid Lat']\n",
    "ds = ds.drop(columns=Cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd66d95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select only numerical features for correlation analysis\n",
    "numerical_dataset = ds.select_dtypes(include=['number'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(numerical_dataset.corr(),\n",
    "            cmap = 'BrBG',\n",
    "            fmt = '.2f',\n",
    "            linewidths = 2,\n",
    "            annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb949090",
   "metadata": {},
   "source": [
    "# Comments:\n",
    "\n",
    "Identifying object, integer, float type columns and assigning them to different subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "626261d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# identifying object type columns\n",
    "obj = (ds.dtypes == 'object')\n",
    "object_cols = list(obj[obj].index)\n",
    "print(\"Categorical variables:\",len(object_cols))\n",
    "\n",
    "# identifying integer type columns\n",
    "int_ = (ds.dtypes == 'int')\n",
    "num_cols = list(int_[int_].index)\n",
    "print(\"Integer variables:\",len(num_cols))\n",
    "\n",
    "# identifying float type columns\n",
    "fl = (ds.dtypes == 'float')\n",
    "fl_cols = list(fl[fl].index)\n",
    "print(\"Float variables:\",len(fl_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b40bbc",
   "metadata": {},
   "source": [
    "# Comments: \n",
    "identifying number of unique categores each object type columns have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4194336e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_values = []\n",
    "for col in object_cols:\n",
    "    unique_values.append(ds[col].unique().size)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('No. Unique values of Categorical Features')\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=object_cols,y=unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7815f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = ds[object_cols].nunique()\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aeca04",
   "metadata": {},
   "source": [
    "# Comments:\n",
    " - Features with a large number of unique categories can be challenging to handle in machine learning models, as they might lead to high-dimensional data.The columns with more than 500 categories may not contribute to AVM. Hence they can be dropped. \n",
    " - Also columns with 1 category were looked into manually in excel file. They were just sigular value against a proprty which would play no role in prediction modelling, so they are dropped.\n",
    " - Columns like Assessed Value, status, Property Class 1, 2,3,4,5 were dropped as we have a condensed column displaying the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df886fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cols_to_drop = ['Full Address','Geometry','Detail URL',\n",
    "                'Assessed Value 1','Assessed Value 2','Assessed Value 3','Assessed Value 4',\n",
    "                'Assessed Value 5','Property Class 1','Property Class 2','Property Class 3',\n",
    "                'Property Class 4','Property Class 5','Status 1','Status 2','Status 3','Status 4',\n",
    "                'Status 5','Roll Number','Unit Number','Street Name','Street Suffix','Dwelling Units',\n",
    "                'Multiple Residences','Property Influences','Number Floors (Condo)']\n",
    "ds = ds.drop(columns=Cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c2876",
   "metadata": {},
   "source": [
    "# One- Hot Encoding for Categorical columns\n",
    "\n",
    "\n",
    "- Low-Cardinality Categorical Columns (≤ 20 unique values)\n",
    "These were one-hot encoded (converted into binary columns):\n",
    "\n",
    "    - Market Region\n",
    "    - Building Type\n",
    "    - Basement\n",
    "    - Basement Finish\n",
    "    - Air Conditioning\n",
    "    - Fire Place\n",
    "    - Attached Garage\n",
    "    - Detached Garage\n",
    "    - Pool\n",
    "    - Property Use Code\n",
    "\n",
    "- High-Cardinality Categorical Columns (> 20 unique values)\n",
    "These were frequency encoded (replaced with the count of each category's occurrence):\n",
    "\n",
    "    - Street Type\n",
    "    - Neighbourhood Area\n",
    "    - Zoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "640c9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop unnamed index column if present\n",
    "ds = ds.loc[:, ~ds.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Identify categorical columns (object or bool types)\n",
    "categorical_cols = ds.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "\n",
    "# Count unique categories in each categorical column\n",
    "category_counts = ds[categorical_cols].nunique()\n",
    "\n",
    "# Separate columns into low and high cardinality\n",
    "low_cardinality = category_counts[category_counts <= 20].index.tolist()\n",
    "high_cardinality = category_counts[category_counts > 20].index.tolist()\n",
    "\n",
    "# One-hot encode low-cardinality categorical columns\n",
    "df_encoded = pd.get_dummies(ds, columns=low_cardinality, drop_first=True)\n",
    "\n",
    "# Frequency encode high-cardinality categorical columns\n",
    "for col in high_cardinality:\n",
    "    freq_encoding = ds[col].value_counts()\n",
    "    df_encoded[col + '_freq'] = ds[col].map(freq_encoding)\n",
    "\n",
    "# Drop original high-cardinality columns\n",
    "df_encoded.drop(columns=high_cardinality, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63753b8e",
   "metadata": {},
   "source": [
    "# Feature Selection, Prediction model and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d897f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Drop rows with missing target values\n",
    "df_encoded = df_encoded.dropna(subset=[\"Total Assessed Value\"])\n",
    "\n",
    "# Select numerical features only\n",
    "numerical_features = df_encoded.select_dtypes(include=[np.number]).drop(columns=[\"Total Assessed Value\"])\n",
    "X = numerical_features\n",
    "y = df_encoded[\"Total Assessed Value\"]\n",
    "\n",
    "# Define scalers\n",
    "scalers = {\n",
    "    \"MinMax\": MinMaxScaler(),\n",
    "    \"ZScore\": StandardScaler()\n",
    "}\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"RF\": RandomForestRegressor(random_state=42),\n",
    "    \"XGB\": XGBRegressor(random_state=42),\n",
    "    \"LR\": LinearRegression()\n",
    "}\n",
    "\n",
    "# Store performance metrics\n",
    "performance = []\n",
    "\n",
    "# Evaluate each model with each scaling method\n",
    "for scale_name, scaler in scalers.items():\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        nrmse = np.sqrt(mean_squared_error(y_test, y_pred)) / (y.max() - y.min())\n",
    "\n",
    "        performance.append({\n",
    "            \"Model\": f\"{model_name}-{scale_name}\",\n",
    "            \"R²\": round(r2, 3),\n",
    "            \"MAPE\": round(mape, 3),\n",
    "            \"nRMSE\": round(nrmse, 3)\n",
    "        })\n",
    "\n",
    "# Create performance comparison table\n",
    "performance_df = pd.DataFrame(performance)\n",
    "\n",
    "# Save the table to CSV\n",
    "performance_df.to_csv(\"model_performance_comparison.csv\", index=False)\n",
    "\n",
    "# Plot feature importances for RF and XGB\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "rf_model.fit(X_scaled, y)\n",
    "xgb_model.fit(X_scaled, y)\n",
    "\n",
    "rf_importance = rf_model.feature_importances_\n",
    "xgb_importance = xgb_model.feature_importances_\n",
    "\n",
    "# Normalize importances\n",
    "rf_norm = rf_importance / rf_importance.sum()\n",
    "xgb_norm = xgb_importance / xgb_importance.sum()\n",
    "\n",
    "# Average importance\n",
    "avg_importance = (rf_norm + xgb_norm) / 2\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"RF Importance\": rf_norm,\n",
    "    \"XGB Importance\": xgb_norm,\n",
    "    \"Average Importance\": avg_importance\n",
    "}).sort_values(by=\"Average Importance\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(importance_df[\"Feature\"][:10], importance_df[\"Average Importance\"][:10])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Top 10 Feature Importances (Average of RF and XGB)\")\n",
    "plt.ylabel(\"Normalized Importance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importance_comparison.png\")\n",
    "\n",
    "# Save importance table\n",
    "importance_df.to_csv(\"feature_importance_comparison.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "addccb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Store runtime and performance metrics\n",
    "runtime_results = []\n",
    "mse_results = []\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate runtime and MSE\n",
    "    runtime = round(end_time - start_time, 4)\n",
    "    mse = round(mean_squared_error(y_test, y_pred), 2)\n",
    "    runtime_results.append({\"Model\": model_name, \"Runtime (s)\": runtime})\n",
    "    mse_results.append({\"Model\": model_name, \"MSE\": mse})\n",
    "\n",
    "    # Scatter plot: Actual vs Predicted\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.xlabel(\"Actual Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.title(f\"{model_name} - Actual vs Predicted\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name.lower().replace(' ', '_')}_actual_vs_predicted.png\")\n",
    "\n",
    "    # Scatter plot: Residuals\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel(\"Predicted Values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(f\"{model_name} - Residuals\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name.lower().replace(' ', '_')}_residuals.png\")\n",
    "\n",
    "# Save runtime and MSE results to CSV\n",
    "pd.DataFrame(runtime_results).to_csv(\"model_runtime_comparison.csv\", index=False)\n",
    "pd.DataFrame(mse_results).to_csv(\"model_mse_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fe2c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script Automated valuation model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde2fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
